{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d2800f-9e68-468a-982d-d4458c755edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "import threading\n",
    "import pickle\n",
    "import pandas\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5eeeb8f-ceb5-427d-b881-ab4bdbd9d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = r'D:\\Ready_Corpus\\corpusForTrain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8708b011-c348-4103-985c-53efe84265dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение файлов\n",
    "def conllu_reader(file: str) -> list:\n",
    "    with open(file, 'r', encoding='utf-8') as in_conllu:\n",
    "        sentences = []\n",
    "        sentence = []\n",
    "        for line in in_conllu:\n",
    "            if line != '\\n':\n",
    "                sentence.append(line.split('\\t'))\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6167e5e4-6661-4354-b716-90c7bf9d22f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# подготовка корпуса\n",
    "def prepare_corpus(file):   \n",
    "           \n",
    "    # columns=['ID', 'word', 'lemma', 'pos', 'smth', 'spec', 'head', 'type']\n",
    "    # search_word - слово для которого мы ищем по корпусу верщины и зависимые\n",
    "    # word - слово, которое мы нашли в предложении\n",
    "\n",
    "    # поиск вершин и зависимых для найденного слова\n",
    "    def potent_searcher(sentence, search_word, position):\n",
    "        # 6 - head\n",
    "        if search_word[6]:\n",
    "            if position == 'head':\n",
    "                file_writer(search_word, sentence[int(search_word[6]) - 1], 'word_head')\n",
    "\n",
    "        if position == 'dependent':\n",
    "            for potent_dependent in sentence:\n",
    "                if potent_dependent[6] == search_word[0]:\n",
    "                    file_writer(search_word, potent_dependent, 'word_dependent')\n",
    "\n",
    "    # подгонка под формат категорий слова\n",
    "    def spec_prepare_for_file(spec):\n",
    "        return '_'.join(spec.split('|'))\n",
    "\n",
    "    # запись слова в файл\n",
    "    def file_writer(search_word, potent_word, position_type):\n",
    "        try:\n",
    "            file_path = os.path.join(FOLDER_PATH, position_type, f'{\"^\".join([search_word[1].lower()] + search_word[2:5] + [spec_prepare_for_file(search_word[5])] + [search_word[7].strip()])}.txt')\n",
    "            with open(file_path, 'a', encoding='utf-8') as out_file:\n",
    "                out_file.write('\\t'.join(potent_word))\n",
    "        except:\n",
    "            print(search_word)\n",
    "\n",
    "    corpus = conllu_reader(file) \n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            threading.Thread(target=potent_searcher, args=(sentence, word, 'head')).start()\n",
    "            threading.Thread(target=potent_searcher, args=(sentence, word, 'dependent')).start()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6dcdcc-b16f-4bd3-8edd-56b4e1053dd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'http://www.armeninews.com', 'HTTP://WWW.ARMENINEWS.COM', 'NID', '_', '_', '9', 'аппоз\\n']\n",
      "['5', 'SAP R/3', 'SAP R/3', 'NID', '_', '_', '2', '1-компл\\n']\n",
      "['5', '1/5', '1/5', 'NUM', '_', '_', '6', 'количест\\n']\n",
      "['33', 'в/ч', 'В/Ч', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '32', 'примыкат\\n']['33', 'в/ч', 'В/Ч', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '32', 'примыкат\\n']\n",
      "\n",
      "['73', 'в/ч', 'В/Ч', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '72', 'примыкат\\n']\n",
      "['73', 'в/ч', 'В/Ч', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '72', 'примыкат\\n']\n",
      "['32', 'кВт/ч', 'КВТ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '31', 'квазиагент\\n']\n",
      "['22', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '20', 'предл\\n']['22', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '20', 'предл\\n']\n",
      "\n",
      "['10', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '6', 'компл-аппоз\\n']\n",
      "['10', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '6', 'компл-аппоз\\n']\n",
      "['10', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '6', 'компл-аппоз\\n']\n",
      "['14', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '12', 'предл\\n']\n",
      "['14', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '12', 'предл\\n']\n",
      "['13', '2/3', '2/3', 'NUM', '_', '_', '12', 'предик\\n']\n",
      "['13', '2/3', '2/3', 'NUM', '_', '_', '12', 'предик\\n']\n",
      "['12', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']['12', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']\n",
      "\n",
      "['18', 'км/с', 'КМ/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '16', 'компл-аппоз\\n']['18', 'км/с', 'КМ/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '16', 'компл-аппоз\\n']\n",
      "\n",
      "['47', '1/3', '1/3', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '51', 'предик\\n']['47', '1/3', '1/3', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '51', 'предик\\n']\n",
      "\n",
      "['47', '1/3', '1/3', 'S', '_', 'ЖЕН|ИМ|ЕД|НЕОД', '51', 'предик\\n']\n",
      "['52', '2/3', '2/3', 'S', '_', 'МН|ЖЕН|ВИН|НЕОД', '51', '1-компл\\n']\n",
      "['52', '2/3', '2/3', 'S', '_', 'МН|ЖЕН|ВИН|НЕОД', '51', '1-компл\\n']\n",
      "['56', '2/3', '2/3', 'S', '_', 'МН|ЖЕН|ИМ|НЕОД', '59', 'предик\\n']\n",
      "['56', '2/3', '2/3', 'S', '_', 'МН|ЖЕН|ИМ|НЕОД', '59', 'предик\\n']\n",
      "['61', '1/3', '1/3', 'S', '_', 'ЖЕН|ВИН|ЕД|НЕОД', '59', '1-компл\\n']\n",
      "['61', '1/3', '1/3', 'S', '_', 'ЖЕН|ВИН|ЕД|НЕОД', '59', '1-компл\\n']\n",
      "['11', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '9', 'компл-аппоз\\n']['11', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '9', 'компл-аппоз\\n']\n",
      "\n",
      "['9', '1/3', '1/3', 'NUM', '_', '_', '11', 'количест\\n']\n",
      "['13', '2/3', '2/3', 'NUM', '_', '_', '14', 'количест\\n']\n",
      "['21', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '19', 'предл\\n']['21', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '19', 'предл\\n']\n",
      "\n",
      "['25', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '22', 'компл-аппоз\\n']\n",
      "['25', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '22', 'компл-аппоз\\n']\n",
      "['14', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '11', '1-компл\\n']\n",
      "['14', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '11', '1-компл\\n']\n",
      "['16', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '14', 'предл\\n']\n",
      "['16', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '14', 'предл\\n']\n",
      "['25', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '23', 'компл-аппоз\\n']\n",
      "['25', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '23', 'компл-аппоз\\n']\n",
      "['12', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', 'предл\\n']\n",
      "['12', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', 'предл\\n']\n",
      "['10', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '8', '1-компл\\n']\n",
      "['10', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '8', '1-компл\\n']\n",
      "['8', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '6', 'сравнит\\n']\n",
      "['8', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '6', 'сравнит\\n']\n",
      "['11', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '9', 'сравнит\\n']\n",
      "['11', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '9', 'сравнит\\n']\n",
      "['23', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '21', 'предл\\n']['23', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '21', 'предл\\n']\n",
      "\n",
      "['16', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '14', 'предл\\n']\n",
      "['16', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '14', 'предл\\n']\n",
      "['16', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '14', '1-компл\\n']\n",
      "['16', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '14', '1-компл\\n']\n",
      "['20', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '18', 'компл-аппоз\\n']['20', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '18', 'компл-аппоз\\n']\n",
      "\n",
      "['8', '9:00', '9:00', 'NUM', '_', '_', '7', 'предл\\n']\n",
      "['4', '18:00', '18:00', 'NUM', '_', '_', '3', 'предл\\n']\n",
      "['12', '1/3', '1/3', 'NUM', '_', '_', '11', 'предик\\n']['12', '1/3', '1/3', 'NUM', '_', '_', '11', 'предик\\n']\n",
      "\n",
      "['20', '5/3', '5/3', 'NUM', '_', '_', '19', 'предик\\n']\n",
      "['20', '5/3', '5/3', 'NUM', '_', '_', '19', 'предик\\n']\n",
      "['12', '23:00', '23:00', 'NUM', '_', '_', '11', 'предл\\n']\n",
      "['14', '6:00', '6:00', 'NUM', '_', '_', '13', 'предл\\n']\n",
      "['15', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']['15', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']\n",
      "\n",
      "['15', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']\n",
      "['15', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']\n",
      "['15', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', '1-компл\\n']\n",
      "['24', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '20', 'соч-союзн\\n']\n",
      "['24', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '20', 'соч-союзн\\n']\n",
      "['7', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '5', 'предл\\n']['7', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '5', 'предл\\n']\n",
      "\n",
      "['23', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '21', 'предл\\n']\n",
      "['23', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '21', 'предл\\n']\n",
      "['11', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '9', 'компл-аппоз\\n']['11', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '9', 'компл-аппоз\\n']\n",
      "\n",
      "['13', 'б/у', 'Б/У', 'A', '_', 'ВИН|СРЕД|ЕД', '12', '1-компл\\n']\n",
      "['5', '2/3', '2/3', 'NUM', '_', '_', '4', '1-компл\\n']['5', '2/3', '2/3', 'NUM', '_', '_', '4', '1-компл\\n']\n",
      "\n",
      "['13', '1 1/2', '1 1/2', 'NUM', '_', '_', '14', 'количест\\n']\n",
      "['13', 'L/D', 'L/D', 'NID', '_', '_', '12', 'примыкат\\n']\n",
      "['8', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '6', '1-компл\\n']\n",
      "['8', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '6', '1-компл\\n']\n",
      "['12', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', 'сравнит\\n']\n",
      "['12', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '10', 'сравнит\\n']\n",
      "['21', 'www.pravmir.ru/pochemu-ya-ne-pravoslavnyj', 'WWW.PRAVMIR.RU\\\\\\\\POCHEMU-YA-NE-PRAVOSLAVNYJ', 'NID', '_', '_', '20', 'примыкат\\n']\n",
      "['13', '*', '*', 'NID', '_', '_', '12', 'аппоз\\n']\n",
      "['26', 'sendsms.megafon.ru/status/send/0123456789ABCDEF', 'SENDSMS.MEGAFONRUSTATUSSEND0123456789ABCDEF', 'NID', '_', '_', '25', 'аппоз\\n']\n",
      "['2', '1/2', '1/2', 'NUM', '_', '_', '3', 'количест\\n']\n",
      "['6', 'и/или', 'И/ИЛИ', 'CONJ', '_', '_', '5', 'сочин\\n']['6', 'и/или', 'И/ИЛИ', 'CONJ', '_', '_', '5', 'сочин\\n']\n",
      "\n",
      "['27', 'и/или', 'И/ИЛИ', 'CONJ', '_', '_', '24', 'сочин\\n']\n",
      "['27', 'и/или', 'И/ИЛИ', 'CONJ', '_', '_', '24', 'сочин\\n']\n",
      "['8', '1/10', '1/10', 'S', '_', 'ЖЕН|ВИН|ЕД|НЕОД', '7', '1-компл\\n']\n",
      "['8', '1/10', '1/10', 'S', '_', 'ЖЕН|ВИН|ЕД|НЕОД', '7', '1-компл\\n']\n",
      "['25', '1/5', '1/5', 'NUM', '_', '_', '24', 'предл\\n']\n",
      "['6', 'бит/с', 'БИТ/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '4', 'компл-аппоз\\n']['6', 'бит/с', 'БИТ/С', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '4', 'компл-аппоз\\n']\n",
      "\n",
      "['10', 'см/сек2', 'СМ/СЕК2', 'S', '_', 'ДАТ|МУЖ|ЕД|НЕОД', '8', '1-компл\\n']['10', 'см/сек2', 'СМ/СЕК2', 'S', '_', 'ДАТ|МУЖ|ЕД|НЕОД', '8', '1-компл\\n']\n",
      "\n",
      "['20', '11:49', '11:49', 'NUM', '_', '_', '19', 'предл\\n']\n",
      "['22', 'http://www.novayagazeta.ru/politics/48277.html', 'HTTP://WWW.NOVAYAGAZETA.RU/POLITICS/48277.HTML', 'NID', '_', '_', '9', 'сочин\\n']\n",
      "['20', 'и/или', 'И/ИЛИ', 'CONJ', '_', '_', '19', 'сочин\\n']['20', 'и/или', 'И/ИЛИ', 'CONJ', '_', '_', '19', 'сочин\\n']\n",
      "\n",
      "['2', '04:26', '04:26', 'NUM', '_', '_', '1', 'предл\\n']['2', '04:26', '04:26', 'NUM', '_', '_', '1', 'предл\\n']\n",
      "\n",
      "['10', '12:20', '12:20', 'NUM', '_', '_', '9', 'предл\\n']\n",
      "['6', '3/4', '3/4', 'NUM', '_', '_', '5', 'предл\\n']\n",
      "['13', '1/3', '1/3', 'NUM', '_', '_', '14', 'количест\\n']\n",
      "['14', '3/4', '3/4', 'NUM', '_', '_', '13', 'предл\\n']\n",
      "['11', '23:30', '23:30', 'NUM', '_', '_', '10', 'предл\\n']\n",
      "['2', '4:30', '4:30', 'NUM', '_', '_', '1', 'предл\\n']['2', '4:30', '4:30', 'NUM', '_', '_', '1', 'предл\\n']\n",
      "\n",
      "['4', '9:02', '9:02', 'NUM', '_', '_', '3', 'предл\\n']['4', '9:02', '9:02', 'NUM', '_', '_', '3', 'предл\\n']\n",
      "\n",
      "['9', '4:02', '4:02', 'NUM', '_', '_', '8', 'предл\\n']\n",
      "['9', '4:02', '4:02', 'NUM', '_', '_', '8', 'предл\\n']\n",
      "['1', 'P4 + 6H2 --> 4PH3', 'P4 + 6H2  --> 4PH3', 'NID', '_', '_', '0', 'root\\n']\n",
      "['2', '23:00', '23:00', 'NUM', '_', '_', '1', 'предл\\n']\n",
      "['16', '23:00', '23:00', 'NUM', '_', '_', '15', 'предл\\n']\n",
      "['21', '22:37', '22:37', 'NUM', '_', '_', '20', 'предл\\n']\n",
      "['4', '3:00', '3:00', 'NUM', '_', '_', '3', 'предл\\n']\n",
      "['4', '3:00', '3:00', 'NUM', '_', '_', '3', 'предл\\n']\n",
      "['12', 'http://www.ortrtr.ru', 'HTTP://WWW.ORTRTR.RU', 'NID', '_', '_', '11', 'аппоз\\n']\n",
      "['6', '15:00', '15:00', 'NUM', '_', '_', '5', 'предл\\n']\n",
      "['8', '15:30', '15:30', 'NUM', '_', '_', '7', 'предл\\n']['8', '15:30', '15:30', 'NUM', '_', '_', '7', 'предл\\n']\n",
      "\n",
      "['14', '9:00', '9:00', 'NUM', '_', '_', '13', 'предл\\n']\n",
      "['16', '13:00', '13:00', 'NUM', '_', '_', '15', 'предл\\n']\n",
      "['19', '13:04', '13:04', 'NUM', '_', '_', '18', 'предл\\n']\n",
      "['19', '13:04', '13:04', 'NUM', '_', '_', '18', 'предл\\n']\n",
      "['20', '08:04', '08:04', 'NUM', '_', '_', '19', 'примыкат\\n']\n",
      "['20', '08:04', '08:04', 'NUM', '_', '_', '19', 'примыкат\\n']\n",
      "['7', '17:04', '17:04', 'NUM', '_', '_', '6', 'предл\\n']\n",
      "['7', '17:04', '17:04', 'NUM', '_', '_', '6', 'предл\\n']\n",
      "['8', '12:04', '12:04', 'NUM', '_', '_', '7', 'примыкат\\n']\n",
      "['8', '12:04', '12:04', 'NUM', '_', '_', '7', 'примыкат\\n']\n",
      "['4', '12:00', '12:00', 'NUM', '_', '_', '3', 'предл\\n']['4', '12:00', '12:00', 'NUM', '_', '_', '3', 'предл\\n']\n",
      "\n",
      "['9', '5:00', '5:00', 'NUM', '_', '_', '8', 'предл\\n']\n",
      "['9', '5:00', '5:00', 'NUM', '_', '_', '8', 'предл\\n']\n",
      "['20', '00:19', '00:19', 'NUM', '_', '_', '19', 'предл\\n']\n",
      "['20', '00:19', '00:19', 'NUM', '_', '_', '19', 'предл\\n']\n",
      "['17', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '14', '1-компл\\n']\n",
      "['17', 'м/с', 'М/С', 'S', '_', 'РОД|МУЖ|ЕД|НЕОД', '14', '1-компл\\n']\n",
      "['6', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '4', 'предл\\n']['6', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '4', 'предл\\n']\n",
      "\n",
      "['24', '12:00', '12:00', 'NUM', '_', '_', '23', 'предл\\n']\n",
      "['8', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '5', 'сравнит\\n']['8', 'км/час', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '5', 'сравнит\\n']\n",
      "\n",
      "['29', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '27', 'компл-аппоз\\n']['29', 'км/ч', 'КМ/Ч', 'S', '_', 'РОД|МУЖ|МН|НЕОД', '27', 'компл-аппоз\\n']\n",
      "\n",
      "CPU times: total: 29min 30s\n",
      "Wall time: 16min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prepare_corpus('syntagrus_train.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b0699a-bfc1-4fa6-be29-42d7aae1f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specFileWriter(in_path, out_path):\n",
    "    for file in os.listdir(os.path.join(FOLDER_PATH, in_path)):\n",
    "        try:\n",
    "            with open(os.path.join(FOLDER_PATH, out_path, '^'.join(file.split('^')[2:])), 'a', encoding='utf-8') as out_file:\n",
    "                with open(os.path.join(FOLDER_PATH, in_path, file), 'r', encoding='utf-8') as in_file:\n",
    "                    try:\n",
    "                        for line in in_file:\n",
    "                            out_file.write(clean_for_spec(line))\n",
    "                    except:\n",
    "                        pass\n",
    "        except:\n",
    "            print(file)\n",
    "                \n",
    "# что-то еще чистим\n",
    "def clean_for_spec(line):\n",
    "    cleaned = list(map(lambda x: x.strip(), line.split('\\t')))\n",
    "    return '\\t'.join([cleaned[3], cleaned[4], cleaned[5], cleaned[7]]) + '\\n' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a3ce85-f844-47c8-b24a-1076b0e581b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about\n",
      "CPU times: total: 4min 29s\n",
      "Wall time: 39min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "specFileWriter('word_head', 'spec_head')\n",
    "specFileWriter('word_dependent', 'spec_dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a02003-bf17-421e-b6d4-8dd7d2aecf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_perMillion_counter():\n",
    "    root_amount = {}\n",
    "    for folder in os.listdir(FOLDER_PATH):\n",
    "        if not folder.endswith('pkl'):\n",
    "            for file in os.listdir(os.path.join(FOLDER_PATH, folder)):\n",
    "                if file.endswith('root.txt'):\n",
    "                    with open(os.path.join(FOLDER_PATH, folder, file), 'rb') as root_file:\n",
    "                        root_counter = len(root_file.readlines())\n",
    "                    files_to_check = [file_name for file_name in os.listdir(os.path.join(FOLDER_PATH, folder)) if file_name.split('^')[:-1] == file.split('^')[:-1] and file_name.split('^')[-1] != 'root.txt']\n",
    "                    other_counter = 0\n",
    "                    for file_to_check in files_to_check:\n",
    "                        with open(os.path.join(FOLDER_PATH, folder, file_to_check), 'rb') as other_file:\n",
    "                            other_counter += len(other_file.readlines())\n",
    "                    other_counter = other_counter if other_counter else 1\n",
    "                    root_amount[file[:-9]] = root_counter / 1000000 / other_counter\n",
    "    return root_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1504a587-6f9a-45ae-9f04-f0086c5c1dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3h 25min 37s\n",
      "Wall time: 3h 41min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "root_posibility = root_perMillion_counter()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a397c6c7-a706-4dc4-b2ad-15c2cec1f123",
   "metadata": {},
   "source": [
    "with open(os.path.join(FOLDER_PATH, 'root_posibility.pkl'), 'wb') as out_file:\n",
    "    pickle.dump(root_posibility, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19c72b1c-ca00-4213-befa-1215d12daa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FOLDER_PATH, 'root_posibility.pkl'), 'rb') as in_file:\n",
    "    root_posibility = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f78eb8f0-0577-4eb2-91ac-fcb34fc7f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_splitter(spec):\n",
    "    return spec.split('|')\n",
    "\n",
    "def preapare_file_name_spec(file_name):\n",
    "    splitted = file_name.split('^')\n",
    "    return file_name.split('^')[:-2] + ['|'.join(splitted[-2].split('_')) if splitted[-2] != '_' else '_']\n",
    "\n",
    "def preapare_file_name(file_name):\n",
    "    splitted = file_name.split('^')\n",
    "    return splitted[:3] + ['_', '|'.join(splitted[4].split('_')) if splitted[4] != '_' else '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed9f52cd-e4c1-46fa-b26f-c9138ad64c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчет близости слова и слова с потенциальной связью\n",
    "def nearest(current_word: list, position: list) -> float:\n",
    "    position = list(map(lambda x: x.strip(), position.split('\\t')))[:-2]\n",
    "    current_word = current_word[:-1]\n",
    "    current_word.extend(spec_splitter(current_word[-1]))\n",
    "    if len(position) == 0: return 0\n",
    "    position = position[:-1]\n",
    "    if len(position) == 0: return 0\n",
    "    position.extend(spec_splitter(position[-1]))\n",
    "    return len(set(current_word) & set(position)) / ((len(current_word) + len(position)) / 2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "146be88a-9cfd-4b76-be20-6154c16f6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем ранги. word - word, top_full - variants_counter[0], variants - variants_counter[1]\n",
    "def is_position(word: list, top_full: list, variants: dict) -> list:\n",
    "    result = []\n",
    "    for top in top_full:\n",
    "        for spec, counter in variants[top[0]].items():\n",
    "            result.append([spec, nearest(word, spec) * counter])\n",
    "            # result.append([spec, nearest(word, spec) / sum(variant[1] for variant in top_full)])\n",
    "    return sorted(result, key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbd5e76b-b5c3-4049-925a-4c424cad40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# по словарю вершин/зависимых слова возвращается сортированный словарь для получения самого вероятного отношеия и весь словарь(хз зачем если честно). variants - head_dep_searcher\n",
    "def variants_counter(variants: list) -> 'dict, list':\n",
    "    variants_counter_dict = {}\n",
    "    for file in variants:\n",
    "        result = []\n",
    "        with open(file, 'rb') as in_file:\n",
    "            for line in in_file:\n",
    "                try: result.append(line.decode('utf-8'))\n",
    "                except: pass\n",
    "            variants_counter_dict[file.split('\\\\')[-1]] = Counter(result)\n",
    "    temp_result = {key: sum(value.values()) for key, value in variants_counter_dict.items()}\n",
    "    return sorted(temp_result.items(), key=lambda x: x[1], reverse=True), variants_counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26803107-bd0d-47ca-b252-4c855c2289ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# по словарю отношений между двумя словами готовится отношение между двумя словами. word1, word2 - word, dep_head_dict - head_dep_searcher\n",
    "def head_dep_marker(dep_head_dict: dict, word1: list, word2: list) -> list:\n",
    "    max_key = max(dep_head_dict, key=lambda x: dep_head_dict[x][0][1] if len(dep_head_dict[x]) else 0)\n",
    "    if max_key in ['word2_head_for_word1', 'word1_dep_for_word2']:\n",
    "        connection = connection_type(word2, word1)\n",
    "        return [[word1, word2[0], connection[0][0] if len(connection) else '???'], [word2, 'free'], dep_head_dict[max_key][0][1] if len(dep_head_dict[max_key]) else 0]\n",
    "    else:\n",
    "        connection = connection_type(word1, word2)\n",
    "        return [[word1, 'free'], [word2, word1[0], connection[0][0] if len(connection) else '???'], dep_head_dict[max_key][0][1] if len(dep_head_dict[max_key]) else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b4b2e11-0810-46ff-902a-2517703e49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяется тип отношений между вершиной и зависмым. head - word, dep - word\n",
    "def connection_type(head: list, dep: list) -> list:\n",
    "    result = []\n",
    "    for file_name in os.listdir(os.path.join(FOLDER_PATH, 'word_dependent')):\n",
    "        if preapare_file_name_spec(file_name) == head[1:]:\n",
    "            with open(os.path.join(FOLDER_PATH, 'word_dependent', file_name), 'r', encoding='utf-8') as words_dep_file:\n",
    "                for word in words_dep_file:\n",
    "                    if dep[1:] == word.split('\\t')[1:-2]:\n",
    "                        result.append(word.split('\\t')[-1].strip())\n",
    "    if not len(result):\n",
    "        for file_name in os.listdir(os.path.join(FOLDER_PATH, 'spec_dependent')):\n",
    "            if preapare_file_name_spec(file_name) == head[3:]:\n",
    "                with open(os.path.join(FOLDER_PATH, 'spec_dependent', file_name), 'r', encoding='utf-8') as spec_dep_file:\n",
    "                    for word in spec_dep_file:\n",
    "                        if dep[3:] == word.split('\\t')[:-1]:\n",
    "                            result.append(word.split('\\t')[-1].strip())\n",
    "    return sorted(list(Counter(result).items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63cdab04-7138-4b3d-ad7e-9bf1858bdc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создается список файлов для вершин и зависимых для слова word - word[1:]\n",
    "def head_dep_searcher(word):\n",
    "    \n",
    "    word_paths = ['word_head', 'word_dependent']\n",
    "    spec_paths = ['spec_head', 'spec_dependent']\n",
    "\n",
    "    head_variants = []\n",
    "    dep_variants = []\n",
    "\n",
    "    for word_path in word_paths:\n",
    "        for file_name in os.listdir(os.path.join(FOLDER_PATH, word_path)):\n",
    "            if preapare_file_name(file_name) == word:\n",
    "                file_path = os.path.join(FOLDER_PATH, word_path, file_name)\n",
    "                head_variants.append(file_path) if word_path == 'word_head' else dep_variants.append(file_path)\n",
    "\n",
    "\n",
    "    for spec_path in spec_paths:\n",
    "        for file_name in os.listdir(os.path.join(FOLDER_PATH, spec_path)):\n",
    "            if preapare_file_name_spec(file_name) == word[2:]:\n",
    "                file_path = os.path.join(FOLDER_PATH, spec_path, file_name)\n",
    "                head_variants.append(file_path) if spec_path == 'spec_head' else dep_variants.append(file_path)\n",
    "\n",
    "    return head_variants, dep_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69e7d62e-68ba-43d3-89de-44a62ed5bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь рангов, word1, word2 - word[1:]\n",
    "def head_dep_rank_counter(word1: list, word2: list) -> dict:\n",
    "    \n",
    "    head_variants_1, dep_variants_1 = head_dep_searcher(word1)\n",
    "    head_variants_2, dep_variants_2 = head_dep_searcher(word2)\n",
    "    \n",
    "    top_heads_1, head_variants_counter_1 = variants_counter(head_variants_1)\n",
    "    top_deps_1, dep_variants_counter_1 = variants_counter(dep_variants_1)\n",
    "    top_heads_2, head_variants_counter_2 = variants_counter(head_variants_2)\n",
    "    top_deps_2, dep_variants_counter_2 = variants_counter(dep_variants_2)\n",
    "    \n",
    "    return {\n",
    "        'word2_head_for_word1': is_position(word2, top_heads_1, head_variants_counter_1),\n",
    "        'word2_dep_for_word1': is_position(word2, top_deps_1, dep_variants_counter_1),\n",
    "        'word1_head_for_word2': is_position(word1, top_heads_2, head_variants_counter_2),\n",
    "        'word1_dep_for_word2': is_position(word1, top_deps_2, dep_variants_counter_2)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5936d16a-0c3f-4103-b390-e1f988dc6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считается вероятность слова быть root, word\n",
    "def is_root_counter(root_posibility: dict, word: list) -> float:\n",
    "    try: return root_posibility['^'.join(word[1:5]) + '^' + '_'.join(word[5].split('|'))]\n",
    "    except: pass\n",
    "    try: return root_posibility['^'.join(word[3:5]) + '^' + '_'.join(word[5].split('|'))]\n",
    "    except: pass\n",
    "    return  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ac4dd9c-1ddb-4fec-a64e-099c1115be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True если нранг новой вершины больше, чем имеющейся\n",
    "def time_to_change(connection: list, rank: float) -> bool:\n",
    "    if type(connection[0]) == tuple:\n",
    "        return connection[0][2] < rank\n",
    "    return connection[1][2] < rank\n",
    "\n",
    "# Проверка на отсутствие вершины у слова\n",
    "def is_free(connection: list) -> bool:\n",
    "    result = True\n",
    "    if type(connection[0]) == tuple or type(connection[1]) == tuple:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc429131-c625-4315-9462-f93e98d552fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск виртуально вершины - на вход words[i][1:]. На выход - virt_N, где N - часть речи\n",
    "def virt_searcher(word: list) -> str:\n",
    "    head, dependent = head_dep_searcher(word)\n",
    "    variants = []\n",
    "    for file in head:\n",
    "        with open(file, 'r', encoding='utf-8') as in_file:\n",
    "            variants.extend([word.strip().split('\\t')[3] if len(word.strip().split('\\t')) == 8 else word.strip().split('\\t')[0] for word in in_file.readlines()])\n",
    "    return 'virt_' + Counter(variants).most_common(1)[0][0] if len(variants) else 'free'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abe8f0c0-132d-4598-bbcb-26de507f53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# построение дерева - scentence - предложение (сырое, без деления), root_posibility - словарь вероятностей быть root, tree_temperature - порог постановления виртуальной вершины\n",
    "def tree_creator(sentence: str, root_posibility: dict, tree_temperature = 0.5) -> dict:\n",
    "    \n",
    "    words = [line.split('\\t')[:-2] for line in sentence.split('\\n')]\n",
    "    \n",
    "    # собираем все варианты отношений и считаем их ранги\n",
    "    all_variants_dict = {}\n",
    "    for i in range(len(words)):\n",
    "        all_variants_dict[words[i][1]] = []\n",
    "        for j in range(i):\n",
    "            all_variants_dict[words[i][1]].append(head_dep_marker(head_dep_rank_counter(words[i][1:], words[j][1:]), words[i], words[j]))\n",
    "\n",
    "    # нормируем для того, чтоб потом постанавливать виртуальные вершины\n",
    "    res = []\n",
    "    counter = 0\n",
    "    for key, value in all_variants_dict.items():\n",
    "        for variant in value:\n",
    "            res.append(variant[-1])\n",
    "    norm_res = preprocessing.normalize([numpy.array(res)])\n",
    "    for key, value in all_variants_dict.items():\n",
    "        for variant in value:\n",
    "            variant[-1] = norm_res[0][counter]\n",
    "            counter += 1\n",
    "\n",
    "    # делаем страшные махинации чтоб расставлять правильные отношения\n",
    "    result = {}\n",
    "    result['\\t'.join(words[0])] = (is_root_counter(root_posibility, words[0]), virt_searcher(words[0][1:]))\n",
    "    max_root = result['\\t'.join(words[0])][0]\n",
    "    for key, values in list(all_variants_dict.items())[1:]:\n",
    "        sorted_result = sorted(values, key=lambda x: x[-1], reverse=True)\n",
    "        for variant in sorted_result:\n",
    "            for elem in variant[:-1]:\n",
    "                is_root = is_root_counter(root_posibility, elem[0])\n",
    "                key = '\\t'.join(elem[0])\n",
    "                virt = virt_searcher(elem[0][1:])\n",
    "                \n",
    "                # новое слово, котрого еще не встроено в дерево\n",
    "                if key not in result: result[key] = (is_root, (elem[1], elem[2], variant[-1])) if elem[1] != 'free' and variant[-1] > tree_temperature else (is_root, virt)\n",
    "                \n",
    "                # у слова стоит маркер free или virt_HEAD\n",
    "                elif is_free(result[key]) and elem[1] != 'free' and variant[-1] > tree_temperature: result[key] = (is_root, (elem[1], elem[2], variant[-1])) if type(result[key][0]) == int or type(result[key][0]) == float else ((elem[1], elem[2], variant[-1]), is_root)\n",
    "                \n",
    "                # у слова уже найдена вершина и найдена новая вершина с более выоским рангом\n",
    "                elif not is_free(result[key]) and elem[1] != 'free' and variant[-1] > tree_temperature and time_to_change(result[key], variant[-1]): result[key] = (is_root, (elem[1], elem[2], variant[-1])) if type(result[key][0]) == int or type(result[key][0]) == float else ((elem[1], elem[2], variant[-1]), is_root)\n",
    "                    \n",
    "            # меняем местами вероятность быть рутом и ранги с отношениями, чтоб максимальная вероятность была справа\n",
    "            for key, value in result.items():\n",
    "                if type(value[0]) == float or type(value[0]) == int:\n",
    "                    if value[0] > max_root:\n",
    "                        result[key] = (value[1], value[0])\n",
    "                        max_root = value[0]\n",
    "                        for little_key, little_value in result.items():\n",
    "                            if little_key != key and type(value[1]) == float or type(value[1]) == int:\n",
    "                                result[little_key] = (value[1], value[0])\n",
    "                elif type(value[1]) == float or type(value[1]) == int:\n",
    "                    if value[1] < max_root:\n",
    "                        result[key] = (value[1], value[0])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a86b0c78-18fd-44dd-b21f-75245240b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для витуальных вершин находим самый вероятный тип отншений - word[1:]\n",
    "def most_popular_connect(word: list) -> str:\n",
    "    result = ''\n",
    "    max_result = 0\n",
    "    for file_name in os.listdir(os.path.join(FOLDER_PATH, 'word_head')):\n",
    "        if preapare_file_name(file_name) == word:\n",
    "            with open(os.path.join(FOLDER_PATH, 'word_head', file_name), 'rb') as word_head_file:\n",
    "                size = len(word_head_file.readlines())\n",
    "                if size > max_result:\n",
    "                    result = file_name.split('^')[-1][:-4]\n",
    "    if not result:\n",
    "        for file_name in os.listdir(os.path.join(FOLDER_PATH, 'spec_head')):\n",
    "            if preapare_file_name_spec(file_name) == word[2:]:\n",
    "                with open(os.path.join(FOLDER_PATH, 'spec_head', file_name), 'rb') as spec_head_file:\n",
    "                    size = len(spec_head_file.readlines())\n",
    "                    if size > max_result:\n",
    "                        result = file_name.split('^')[-1][:-4]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc4c0b62-ce24-466e-9f80-7628737887fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразавное raw-вида дереа в человекопонятный формат. tree - результат выполнения tree_creator\n",
    "def tree_shower(tree: dict, isPrinter = False) -> None:\n",
    "    adder_counter = 1\n",
    "    adder = []\n",
    "    ready_sent = []\n",
    "    for word, head in tree.items():\n",
    "        word_line = []\n",
    "        word_line.append(word)\n",
    "        if type(head[0]) == float or type(head[0]) == int:\n",
    "            if type(head[1]) == tuple:\n",
    "                word_line.extend(list(map(str, head[1])))\n",
    "            else:\n",
    "                adder.append([str(len(tree.keys()) + adder_counter), head[1], head[1], head[1].split('_')[1], '_', 'used'])\n",
    "                word_line.extend([str(len(tree.keys()) + adder_counter), most_popular_connect(word.split('\\t')[1:])])  \n",
    "                adder_counter += 1\n",
    "        else:\n",
    "             word_line.extend(['0', 'root'])\n",
    "        ready_sent.append(word_line)\n",
    "    ready_sent.extend(adder)\n",
    "    \n",
    "    if isPrinter:\n",
    "        print('\\n'.join('\\t'.join(word) for word in ready_sent))\n",
    "    else:\n",
    "        with open(os.path.join('predicted', 'syntagrus_test.conll.predicted'), 'a', encoding='utf-8') as out_file:\n",
    "            out_file.write('\\n'.join('\\t'.join(word) for word in ready_sent))\n",
    "            out_file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5493d8f1-fa04-4411-a5c2-5833ef78025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_pred = conllu_reader('predicted/syntagrus_test.conll.predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b541753-1730-43bd-b551-d05f08b1d5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'А', 'А', 'CONJ', '_', '_', '0', 'root\\n'],\n",
       " ['2', 'ОН', 'ОН', 'S', '_', 'МУЖ|ИМ|ОД|ЕД', '4', 'предик\\n'],\n",
       " ['3', 'МЯТЕЖНЫЙ', 'МЯТЕЖНЫЙ', 'A', '_', 'МУЖ|ИМ|ЕД', '2', 'оп-опред\\n'],\n",
       " ['4',\n",
       "  'ПРОСИТ',\n",
       "  'ПРОСИТЬ',\n",
       "  'V',\n",
       "  '_',\n",
       "  'ЕД|НЕСОВ|НЕПРОШ|ИЗЪЯВ|3-Л',\n",
       "  '1',\n",
       "  'соч-союзн\\n'],\n",
       " ['5', 'БУРИ', 'БУРЯ', 'S', '_', 'ЖЕН|РОД|ЕД|НЕОД', '4', '1-компл\\n']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a605699-17df-48b9-b43e-fa9dbaa23d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''1\tВ общей сложности\tВ ОБЩЕЙ СЛОЖНОСТИ\tADV\t_\t_\t3\tобст\n",
    "2\tэкспедиция\tЭКСПЕДИЦИЯ\tS\t_\tЖЕН|ИМ|ЕД|НЕОД\t3\tпредик\n",
    "3\tдлилась\tДЛИТЬСЯ\tV\t_\tЕД|НЕСОВ|ЖЕН|ПРОШ|ИЗЪЯВ\t0\troot\n",
    "4\tболее\tБОЛЕЕ\tADV\t_\t_\t3\t1-компл\n",
    "5\tвосьми\tВОСЕМЬ\tNUM\t_\tРОД\t6\tколичест\n",
    "6\tлет\tГОД\tS\t_\tРОД|МУЖ|МН|НЕОД\t4\tсравнит'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44857eed-9f1b-49b4-bdaa-ebba4e370ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [line.split('\\t') for line in test.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "074b0b56-18c5-4881-9cf5-669dd75ded01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tВ общей сложности\tВ ОБЩЕЙ СЛОЖНОСТИ\tADV\t_\t_\t3\tэксплет\n",
      "2\tэкспедиция\tЭКСПЕДИЦИЯ\tS\t_\tЖЕН|ИМ|ЕД|НЕОД\t0\troot\n",
      "3\tvirt_V\tvirt_V\tV\t_\tused\n",
      "\n",
      "\n",
      "1\tВ общей сложности\tВ ОБЩЕЙ СЛОЖНОСТИ\tADV\t_\t_\t3\tобст\t0.6036069242384022\n",
      "2\tэкспедиция\tЭКСПЕДИЦИЯ\tS\t_\tЖЕН|ИМ|ЕД|НЕОД\t3\tпредик\t0.793897784144311\n",
      "3\tдлилась\tДЛИТЬСЯ\tV\t_\tЕД|НЕСОВ|ЖЕН|ПРОШ|ИЗЪЯВ\t0\troot\n",
      "\n",
      "\n",
      "1\tВ общей сложности\tВ ОБЩЕЙ СЛОЖНОСТИ\tADV\t_\t_\t3\tобст\t0.48281556879062293\n",
      "2\tэкспедиция\tЭКСПЕДИЦИЯ\tS\t_\tЖЕН|ИМ|ЕД|НЕОД\t3\tпредик\t0.6350261980458313\n",
      "3\tдлилась\tДЛИТЬСЯ\tV\t_\tЕД|НЕСОВ|ЖЕН|ПРОШ|ИЗЪЯВ\t0\troot\n",
      "4\tболее\tБОЛЕЕ\tADV\t_\t_\t3\tобст\t0.48281556879062293\n",
      "\n",
      "\n",
      "1\tВ общей сложности\tВ ОБЩЕЙ СЛОЖНОСТИ\tADV\t_\t_\t3\tобст\t0.48160227942886447\n",
      "2\tэкспедиция\tЭКСПЕДИЦИЯ\tS\t_\tЖЕН|ИМ|ЕД|НЕОД\t3\tпредик\t0.6334304116206817\n",
      "3\tдлилась\tДЛИТЬСЯ\tV\t_\tЕД|НЕСОВ|ЖЕН|ПРОШ|ИЗЪЯВ\t0\troot\n",
      "4\tболее\tБОЛЕЕ\tADV\t_\t_\t3\tобст\t0.48160227942886447\n",
      "5\tвосьми\tВОСЕМЬ\tNUM\t_\tРОД\t6\tпредл\n",
      "6\tvirt_S\tvirt_S\tS\t_\tused\n",
      "\n",
      "\n",
      "1\tВ общей сложности\tВ ОБЩЕЙ СЛОЖНОСТИ\tADV\t_\t_\t3\tобст\t0.42380126656215983\n",
      "2\tэкспедиция\tЭКСПЕДИЦИЯ\tS\t_\tЖЕН|ИМ|ЕД|НЕОД\t3\tпредик\t0.5574072677608384\n",
      "3\tдлилась\tДЛИТЬСЯ\tV\t_\tЕД|НЕСОВ|ЖЕН|ПРОШ|ИЗЪЯВ\t0\troot\n",
      "4\tболее\tБОЛЕЕ\tADV\t_\t_\t3\tобст\t0.42380126656215983\n",
      "5\tвосьми\tВОСЕМЬ\tNUM\t_\tРОД\t6\tколичест\t0.30534906512136545\n",
      "6\tлет\tГОД\tS\t_\tРОД|МУЖ|МН|НЕОД\t3\t1-компл\t0.3351515379785376\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(words) + 1):\n",
    "    tree_shower(tree_creator('\\n'.join('\\t'.join(word).strip() for word in words[:i]), root_posibility, 0.1), True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58efaaa9-4877-4065-ac01-74b38d6df75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = conllu_reader('syntagrus_test.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f43f9454-8dac-490c-9e9b-31fdc370ae89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluator_freq(gold, test):\n",
    "    \n",
    "    true_head = 0\n",
    "    true_head_type = 0\n",
    "    words = 0\n",
    "    \n",
    "    short_true_head = 0\n",
    "    short_true_head_type = 0\n",
    "    short_words = 0\n",
    "        \n",
    "    for test_sentence in test:\n",
    "        for gold_sentence in gold:\n",
    "            if list(map(lambda x: x[0:6], test_sentence))[:len(gold_sentence)] == list(map(lambda x: x[0:6], gold_sentence)):\n",
    "                for i in range(len(gold_sentence)):\n",
    "                    if test_sentence[i][6] == gold_sentence[i][6]:\n",
    "                        if len(gold_sentence) < 10: short_true_head += 1\n",
    "                        true_head += 1\n",
    "                        if test_sentence[i][7] == gold_sentence[i][7]:\n",
    "                            if len(gold_sentence) < 10: short_true_head_type += 1\n",
    "                            true_head_type += 1\n",
    "                    words += 1\n",
    "                    if len(gold_sentence) < 10: short_words += 1\n",
    "    \n",
    "    return true_head / words, true_head_type / words, short_true_head / short_words, short_true_head_type / short_words\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53ba6ac6-6542-49a8-93c2-c8431ae22b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(start, end, sentences):\n",
    "    for i in range(start, end):\n",
    "        print(i, end=' ')\n",
    "        try: tree_shower(tree_creator('\\n'.join('\\t'.join(word).strip() for word in sentences[i]), root_posibility, 0.1))\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480fd04-4b40-4b4f-be15-e0ba63a1ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 "
     ]
    }
   ],
   "source": [
    "predictor(0, len(test_sentences), test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6edd4-1d7f-4314-b262-8733b2fb6159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8a18b25-f6cc-4c75-8bf1-86f8a62f21f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2008230452674897,\n",
       " 0.04691358024691358,\n",
       " 0.3589108910891089,\n",
       " 0.0891089108910891)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_freq(test_sentences, test_sentences_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235cf4b-5ea7-47c0-8251-67d7de4fe824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация словаря количества зависимых с определенными отшениями\n",
    "def connect_type_amounter():\n",
    "    sentences = conllu_reader(r'D:/Ready_Corpus/syntagrus_train.conll')\n",
    "    dep_amount = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            dep = [dep[1:] for dep in sentence if dep[6] == word[0]]\n",
    "            key_word = '^'.join(word[1:-2])\n",
    "            if key_word not in dep_amount: dep_amount[key_word] = {}\n",
    "            if len(dep):\n",
    "                if len(dep) not in dep_amount[key_word]: dep_amount[key_word][len(dep)] = {}\n",
    "                little_key = ' - '.join(sorted([depe[-1].strip() for depe in dep]))\n",
    "                if little_key not in dep_amount[key_word][len(dep)]: dep_amount[key_word][len(dep)][little_key] = 1\n",
    "                else: dep_amount[key_word][len(dep)][little_key] += 1\n",
    "            else:\n",
    "                if len(dep) not in dep_amount[key_word]: dep_amount[key_word][len(dep)] = {'none' : 0}\n",
    "                dep_amount[key_word][len(dep)]['none'] += 1\n",
    "\n",
    "            key_spec = '^'.join(word[3:-2])\n",
    "            if key_spec not in dep_amount: dep_amount[key_spec] = {}\n",
    "            if len(dep):\n",
    "                if len(dep) not in dep_amount[key_spec]: dep_amount[key_spec][len(dep)] = {}\n",
    "                little_key = ' - '.join(sorted([depe[-1].strip() for depe in dep]))\n",
    "                if little_key not in dep_amount[key_spec][len(dep)]: dep_amount[key_spec][len(dep)][little_key] = 1\n",
    "                else: dep_amount[key_spec][len(dep)][little_key] += 1\n",
    "            else:\n",
    "                if len(dep) not in dep_amount[key_spec]: dep_amount[key_spec][len(dep)] = {'none' : 0}\n",
    "                dep_amount[key_spec][len(dep)]['none'] += 1\n",
    "                \n",
    "    result = {}\n",
    "    for key, value in dep_amount.items():\n",
    "        if key not in result: result[key] = {}\n",
    "        for amount, var_list in dep_amount[key].items():\n",
    "            result[key][amount] = dict(sorted(var_list.items(), key=lambda x: x[1], reverse=True))\n",
    "    del dep_amount\n",
    "    for key in result:\n",
    "        result[key] = dict(sorted(result[key].items(), key=lambda x: sum(list(x[1].values())[:len(x[1].values()) // 2]) if len(x[1].values()) > 1 else list(x[1].values())[0], reverse=True))\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
